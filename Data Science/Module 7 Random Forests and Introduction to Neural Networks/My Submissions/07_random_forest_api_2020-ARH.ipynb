{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVr8zdh7yYyq"
   },
   "source": [
    "# Project 7: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IftGNsWyYys"
   },
   "source": [
    "![](https://ars.els-cdn.com/content/image/1-s2.0-S0031320310003973-gr1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tz3Kx17XyYyt"
   },
   "source": [
    "## Instructions\n",
    "\n",
    "### Description\n",
    "\n",
    "In this project, we are going to explore Random Forest Regressors for predicting the weather, specifically the temperature. You'll load the data in, set up a Random Forest, then test its performance on both the original data set and new data. This new data will be the current weather conditions and will come from an Application Programming Interface(API).\n",
    "\n",
    "### Grading\n",
    "\n",
    "For grading purposes, we will clear all outputs from all your cells and then run them all from the top.  Please test your notebook in the same fashion before turning it in.\n",
    "\n",
    "### Submitting Your Solution\n",
    "\n",
    "To submit your notebook, first clear all the cells (this won't matter too much this time, but for larger data sets in the future, it will make the file smaller).  Then use the File->Download As->Notebook to obtain the notebook file.  Finally, submit the notebook file on Canvas.\n",
    "\n",
    "## Side note:\n",
    "Most of the tasks below require you use specific variable names. This is so that the cells with \"assert\" statements in them can check if you did the tasks correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5w9JS-bByYyt"
   },
   "outputs": [],
   "source": [
    "# this might be necessary\n",
    "#!pip3 install pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZMEvefeyYyu"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pydot\n",
    "import requests\n",
    "import graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, explained_variance_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzFUe1LYyYyu"
   },
   "source": [
    "## Loading the data\n",
    "You're given a csv file, ```temps.csv```, with weather data in Seattle from 2016.\n",
    "\n",
    "## Tasks:\n",
    "- Read in the file into a dataframe called `data` DONE\n",
    "- Run `get_dummies()` on the day of the week DONE\n",
    "- Specify the predictors (features) and targets:\n",
    " - Predictors: 'temp_1', 'temp_2', 'average', and the days of the week DONE\n",
    " - Target: 'actual' (the actual temperature on the specified date) DONE\n",
    "- Split the data into training and testing sets DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P9aeRVR2yYyv"
   },
   "outputs": [],
   "source": [
    "# read csv\n",
    "data = pd.read_csv('temps.csv')\n",
    "# data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get_dummies\n",
    "data = pd.get_dummies(data,['week'])\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "features = data[['temp_2', 'temp_1', 'average', 'week_Fri', 'week_Mon', 'week_Sat', 'week_Thurs', 'week_Sun', 'week_Tues', 'week_Wed']]\n",
    "target = data['actual']\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "id": "tPFPTSqZyYyv"
   },
   "outputs": [],
   "source": [
    "for column in ['week_Fri', 'week_Mon', 'week_Sat', 'week_Thurs', 'week_Sun', 'week_Tues', 'week_Wed']:\n",
    "    assert column in data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1X3MZyJ-yYyv"
   },
   "source": [
    "## Random Forest \n",
    "\n",
    "### Background\n",
    "Random Forests, aka Random Decision Trees, are an example of \"ensemble: learning methods. They operate by constructing many decision trees at once and outputting their mean prediction. This is useful because decision trees on their own are prone to overfitting. Random Forests are most often used for classification and regression, but today, we'll only be doing regression.\n",
    "\n",
    "### Tasks \n",
    "- Initialize a `RandomForestRegressor` with 1000 estimators and a max_depth of 10. The model will perform well with these values, but you can always change them later. Store the regressor in the variable `rf_clf`. DONE\n",
    " - https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html \n",
    "- Fit the model with `rf_clf.fit()` DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67JYTRDOyYyw"
   },
   "outputs": [],
   "source": [
    "## initialize model\n",
    "rf_clf = RandomForestRegressor(n_estimators=1000, max_depth=10, random_state=42) #random_state=42\n",
    "rf_clf.fit(features_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ag5Nbn-eyYyw"
   },
   "outputs": [],
   "source": [
    "## training\n",
    "# #got error in visualization: ValueError: Length of feature_names, 348 does not match number of features, 10\n",
    "# target_train.values.flatten()\n",
    "\n",
    "#this did not fix the error I got in the next code... had to add a feature name list and I saw no error for the fit func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLpbSJnJyYyw"
   },
   "source": [
    "## Tree Visualization\n",
    "\n",
    "The next cell plots an image of one of the trees in the forest. It also  \n",
    "saves a png image file in the same directory as this jupyter notebook file. DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3l9CueTayYyw",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot a decision tree\n",
    "\n",
    "feat_names = ['temp_2', 'temp_1', 'average', 'week_Fri', 'week_Mon', 'week_Sat', 'week_Thurs', 'week_Sun', 'week_Tues', 'week_Wed']\n",
    "index = 5\n",
    "tree = rf_clf.estimators_[index]\n",
    "from IPython.display import display\n",
    "columns = list(features_train.columns)\n",
    "display(graphviz.Source(export_graphviz(tree, feature_names=feat_names, class_names=True, out_file=None)))\n",
    "\n",
    "# Save image to png file\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = feat_names, rounded = True, precision = 1)\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YbqEG-PyYyx"
   },
   "source": [
    "## Importance Visualization\n",
    "\n",
    "Plot the learned importance of the features DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qt-ZAA0ZyYyx"
   },
   "outputs": [],
   "source": [
    "# Plot importances\n",
    "importances = list(rf_clf.feature_importances_)\n",
    "labeled_importances = [(feature, round(importance, 2)) for feature, importance in zip(features, importances)]\n",
    "indices = range(len(importances))\n",
    "plt.bar(indices, importances, orientation = 'vertical')\n",
    "plt.title('feature importances')\n",
    "plt.xticks(indices, features, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-v8EfwRhyYyx"
   },
   "source": [
    "## Testing\n",
    "First, we are going to use the test set to make predictions, same as always. Then we're going to get new data from an API.\n",
    "\n",
    "### Tasks\n",
    "- Find the R^2 value. Do this with `model.score()` or `sklearn.metrics.r2_score()` and save to a variable called `r2`. DONE\n",
    "- Find the explained variance with `sklearn.metrics.explained_variance_score()` and save to a variable called `ev`. DONE\n",
    "\n",
    "For both of these metrics, the closer to 1, the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-79j52OyYyy"
   },
   "outputs": [],
   "source": [
    "#predictions \n",
    "# help(r2_score)\n",
    "\n",
    "target_test_hat = rf_clf.predict(features_test)\n",
    "\n",
    "r2 = r2_score(target_test, target_test_hat)\n",
    "\n",
    "print(r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = explained_variance_score(target_test, target_test_hat)\n",
    "print(ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "id": "nPlYDtgfyYyy"
   },
   "outputs": [],
   "source": [
    "assert r2 > 0.7\n",
    "assert ev > 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XREdqjP9yYyy"
   },
   "source": [
    "### API\n",
    "#### Background\n",
    "An application programming interface (API) is just another way to gather data by letting clients (us and our computers) programmatically interact with servers. Today, we're going to be using a weather API for getting the current temp of a location.\n",
    "\n",
    "##### JSON\n",
    "JavaScript Object Notation is a very popular data format, especially for APIs. It appears very similar to Python's dictionaries, with curly braces to start, then key-value pairs of data. An example for a person could be:\n",
    "```\n",
    "{\n",
    "    'firstname': 'John',\n",
    "    'lastname': 'Doe',\n",
    "    'age': 55,\n",
    "    'retired': true,\n",
    "    'addresses': ['123 street', '456 street']\n",
    "}\n",
    "```\n",
    "When we make an API request, the server will handle it, then respond with a bunch of JSON, which we can grab exactly what we want from.\n",
    "\n",
    "#### OpenWeatherMap API\n",
    "Let's use the OpenWeatherMap API to get the current weather. The documentation is [here](https://openweathermap.org/current). To do so, we use the `requests` library. Making a request is very similar to going to a website in a browser -- a URL points to a location or resource on a server and that server fulfills the tasks we ask it to.\n",
    "<br>\n",
    "The URL is `'http://api.openweathermap.org/data/2.5/weather?q={city name},{country code}'`, where we fill in the city name and country code(without the curly braces).\n",
    "<br>\n",
    "An example response the API would send: https://samples.openweathermap.org/data/2.5/weather?q=London,uk&appid=b6907d289e10d714a6e88b30761fae22\n",
    "\n",
    "\n",
    "#### Your tasks\n",
    "- Fill in the URL with the city and country_code. Set this to variable `url`. DONE\n",
    "- Use `requests.get()` to make request. Set the output to variable `r`. This takes two arguments: one called `url`, which is the URL above, and one called `params`, which is a dictionary of parameters, which in this case (and with most APIs) is a unique key that authenticates us and is an indication to use imperial units instead of Kelvin. DONE\n",
    "- Read the response with `r.text` DONE\n",
    "- Parse the response into JSON with `json.loads(response)` DONE\n",
    "- If you want, print the JSON out, formatted nicely with `pprint(response)` DONE\n",
    "- Get the current temperature from the JSON like you would a python dictionary. For example, `person['age']` if we were using the example JSON above. Set this value to the variable `current_temp` DONE\n",
    "- Compare the current temperature to the predicted value. DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fOO6-mz2yYyz"
   },
   "outputs": [],
   "source": [
    "city = 'seattle'\n",
    "country_code = 'us'\n",
    "url = f'http://api.openweathermap.org/data/2.5/weather?q={city},{country_code}'\n",
    "parameters = {\n",
    "    'APPID' : '2dbcde0477e10f32f587960671d2f32e',\n",
    "    'units' : 'imperial'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(requests.get)\n",
    "r = requests.get(url, params=parameters)\n",
    "# r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = json.loads(r.text)\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_temp = response['main']['temp']\n",
    "current_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test_hat #where my predicted temperatures are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to find predicted temp based on what we found in response\n",
    "feat_names = ['temp_2', 'temp_1', 'average', 'week_Fri', 'week_Mon', 'week_Sat', 'week_Thurs', 'week_Sun', 'week_Tues', 'week_Wed']\n",
    "today= 'week_Tues'\n",
    "feat_values = [response['main']['temp_min'], response['main']['temp_max'], response['main']['temp'],]\n",
    "\n",
    "# Set all week_* values to zero except for today\n",
    "for day in feat_names[3:]:\n",
    "    if day == today:\n",
    "        feat_values.append(1)  #1 for today, 0 for not today\n",
    "    else:\n",
    "        feat_values.append(0)\n",
    "\n",
    "    \n",
    "#predict the temp\n",
    "try:\n",
    "    feat_try = np.array([feat_values])\n",
    "    predtemp = rf_clf.predict(feat_try)\n",
    "    print('Predicted Temperature:', predtemp[0])\n",
    "except Exception as e:\n",
    "    print('An error occurred:', str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the current temperature to the predicted value.\n",
    "print(f'Temperature based on feeding current values into model: {round(predtemp[0],2)}')\n",
    "print(f'Actual temperature: {current_temp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "id": "vjPvCP_8yYyz"
   },
   "outputs": [],
   "source": [
    "assert response\n",
    "assert current_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXKAqAbpyYyz"
   },
   "source": [
    "Now we want to compare current weather data to last year. The code given below gets the day of the year it is today, extracts that row from our original csv data, and splits that row into features and targets.\n",
    "\n",
    "#### Your task\n",
    "- Use the your random forest model to predict the temperature on this day last year and compare that prediction to the current temperature.\n",
    "- Divide that comparision (the difference) by the current temperature to determine what percent error we have. Save this to the variable `error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UqoqE3bHyYyz",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "day_of_year = datetime.now().timetuple().tm_yday\n",
    "# print(day_of_year)\n",
    "last_year_features = data.loc[[day_of_year], :] #technically we should -1 because the index starts at 0\n",
    "# last_year_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LYF_try=last_year_features[['temp_2', 'temp_1', 'average', 'week_Fri', 'week_Mon', 'week_Sat', 'week_Thurs', 'week_Sun', 'week_Tues', 'week_Wed']].copy()\n",
    "# LYF_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "#predict the temp\n",
    "try:\n",
    "    temp_pred_today = rf_clf.predict(LYF_try)\n",
    "    print('Predicted Temperature based on DataFrame values from Today:', temp_pred_today)\n",
    "except Exception as e:\n",
    "    print('An error occurred:', str(e))\n",
    "    \n",
    "print(f'Actual temperature: {current_temp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = 100*abs(temp_pred_today[0]-current_temp)/current_temp\n",
    "error = round(error,2)\n",
    "print(f'{error}% error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "id": "cMZQc2K7yYyz"
   },
   "outputs": [],
   "source": [
    "assert error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8h7QP5xyYy0"
   },
   "source": [
    "**Note**: This isn't really the error, since we're compaing the same day in different years. This is due to the limitations of the free tier of this API, but we can still get a *decent* idea of how well the model faired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0O0cf10yYy0"
   },
   "source": [
    "## Reflection Questions\n",
    "\n",
    "Save your response to the questions below in the variable `response`, in the next cell.\n",
    "- Do you think the model did \"well\"? Why or why not?\n",
    "- Whether or not the model did well, what are some ways we could make it even better?\n",
    "- What are some limitations to this model? Could we avoid/prevent them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mf93RTmJyYy0"
   },
   "outputs": [],
   "source": [
    "response = '''I think the model did \"okay\", it was able to predict a realistic temperature. \n",
    "            with a ~3% error. I think the model should be based on the time of year. \n",
    "            Basing it just on weekday is not going to be that useful given the changing\n",
    "            of seasons could lead to a wide spread of temperatures just based off day of week. We should\n",
    "            have included the month in our data set to help. The limitation here is the amount of data.\n",
    "            If we could get more years worth of data then I think there would be enough points to train\n",
    "            with month as a feature. Also, it looks like we are missing days. When we used day_of_year \n",
    "            to find the indexed location, it might not have actually been the 276th day. I beleive I was returned\n",
    "            October 20th. I could have written the code to make sure we found October 3rd, but I do not think\n",
    "            that was needed for the assignment.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "id": "nloqJK_PyYy0"
   },
   "outputs": [],
   "source": [
    "assert len(response) > 50"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Edit Metadata",
  "colab": {
   "collapsed_sections": [],
   "name": "07-random-forest-api-2020.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
